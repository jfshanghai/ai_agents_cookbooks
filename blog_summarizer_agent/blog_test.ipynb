{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies: llama-index llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yujian/Documents/workspace/ai_agents_cookbooks/blog/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot query field 'id' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:61:11\n",
      "60 |         descendants {\n",
      "61 |           id\n",
      "   |           ^\n",
      "62 |           spanKind\n",
      "Cannot query field 'spanKind' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:62:11\n",
      "61 |           id\n",
      "62 |           spanKind\n",
      "   |           ^\n",
      "63 |           name\n",
      "Cannot query field 'name' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:63:11\n",
      "62 |           spanKind\n",
      "63 |           name\n",
      "   |           ^\n",
      "64 |           statusCode: propagatedStatusCode\n",
      "Cannot query field 'propagatedStatusCode' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:64:11\n",
      "63 |           name\n",
      "64 |           statusCode: propagatedStatusCode\n",
      "   |           ^\n",
      "65 |           startTime\n",
      "Cannot query field 'startTime' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:65:11\n",
      "64 |           statusCode: propagatedStatusCode\n",
      "65 |           startTime\n",
      "   |           ^\n",
      "66 |           latencyMs\n",
      "Cannot query field 'latencyMs' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:66:11\n",
      "65 |           startTime\n",
      "66 |           latencyMs\n",
      "   |           ^\n",
      "67 |           parentId\n",
      "Cannot query field 'parentId' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:67:11\n",
      "66 |           latencyMs\n",
      "67 |           parentId\n",
      "   |           ^\n",
      "68 |           cumulativeTokenCountTotal: tokenCountTotal\n",
      "Cannot query field 'tokenCountTotal' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:68:11\n",
      "67 |           parentId\n",
      "68 |           cumulativeTokenCountTotal: tokenCountTotal\n",
      "   |           ^\n",
      "69 |           cumulativeTokenCountPrompt: tokenCountPrompt\n",
      "Cannot query field 'tokenCountPrompt' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:69:11\n",
      "68 |           cumulativeTokenCountTotal: tokenCountTotal\n",
      "69 |           cumulativeTokenCountPrompt: tokenCountPrompt\n",
      "   |           ^\n",
      "70 |           cumulativeTokenCountCompletion: tokenCountCompletion\n",
      "Cannot query field 'tokenCountCompletion' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:70:11\n",
      "69 |           cumulativeTokenCountPrompt: tokenCountPrompt\n",
      "70 |           cumulativeTokenCountCompletion: tokenCountCompletion\n",
      "   |           ^\n",
      "71 |           input {\n",
      "Cannot query field 'input' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:71:11\n",
      "70 |           cumulativeTokenCountCompletion: tokenCountCompletion\n",
      "71 |           input {\n",
      "   |           ^\n",
      "72 |             value\n",
      "Cannot query field 'output' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:74:11\n",
      "73 |           }\n",
      "74 |           output {\n",
      "   |           ^\n",
      "75 |             value\n",
      "Cannot query field 'context' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:77:11\n",
      "76 |           }\n",
      "77 |           context {\n",
      "   |           ^\n",
      "78 |             spanId\n",
      "Cannot query field 'spanAnnotations' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:81:11\n",
      "80 |           }\n",
      "81 |           spanAnnotations {\n",
      "   |           ^\n",
      "82 |             name\n",
      "Cannot query field 'documentRetrievalMetrics' on type 'SpanConnection'.\n",
      "\n",
      "GraphQL request:87:11\n",
      "86 |           }\n",
      "87 |           documentRetrievalMetrics {\n",
      "   |           ^\n",
      "88 |             evaluationName\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: default\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register()\n",
    "LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "# Create an llm object to use for the QueryEngine and the ReActAgent\n",
    "llm = OpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agentic_rag.md',\n",
       " 'multiagent_finetuning.md',\n",
       " 'how_we_scaled_support_without_slowing_down.md',\n",
       " 'unified_tool_for_evalution_and_observability.md',\n",
       " 'agent_router_best_practices.md',\n",
       " 'exploring_deepseek.md',\n",
       " 'memory_and_state_in_llm_applications.md',\n",
       " 'how_to_build_an_ai_agent.md']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_docs = os.listdir(\"arize_blogs/\")\n",
    "input_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_map = {}\n",
    "for doc in input_docs:\n",
    "    data = SimpleDirectoryReader(\n",
    "        input_files=[f\"./arize_blogs/{doc}\"]\n",
    "    ).load_data()\n",
    "    doc_map[doc] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_map = {}\n",
    "for doc in doc_map:\n",
    "    try:\n",
    "        storage_context = StorageContext.from_defaults(\n",
    "            persist_dir=f\"./arize_blog_indexes/{doc}\"\n",
    "        )\n",
    "        vector_index = load_index_from_storage(storage_context)\n",
    "    except:\n",
    "        vector_index = VectorStoreIndex.from_documents(doc_map[doc], show_progress=True)\n",
    "    index_map[doc] = vector_index\n",
    "    vector_index.storage_context.persist(persist_dir=f\"./arize_blog_indexes/{doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = {}\n",
    "for index in index_map:\n",
    "    engines[index] = index_map[index].as_query_engine(similarity_top_k=3, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agentic_rag.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1371d5fd0>,\n",
       " 'multiagent_finetuning.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x135e8e030>,\n",
       " 'how_we_scaled_support_without_slowing_down.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373c9cd0>,\n",
       " 'unified_tool_for_evalution_and_observability.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373bc650>,\n",
       " 'agent_router_best_practices.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373bc050>,\n",
       " 'exploring_deepseek.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373d2f30>,\n",
       " 'memory_and_state_in_llm_applications.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373d3050>,\n",
       " 'how_to_build_an_ai_agent.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373d2db0>}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='The article discusses the concept of Agentic Retrieval-Augmented Generation (RAG), an advancement in AI applications that introduces intelligent agents into the retrieval process, enhancing the handling of complex queries across multiple data sources. It provides a detailed guide on implementing Agentic RAG, emphasizing the importance of clear tool descriptions, robust testing, document quality, and a comprehensive monitoring strategy for system performance.')]), raw=ChatCompletion(id='chatcmpl-BBTyZvVNbsLQ4XwcBTGLSmFOu0KKU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The article discusses the concept of Agentic Retrieval-Augmented Generation (RAG), an advancement in AI applications that introduces intelligent agents into the retrieval process, enhancing the handling of complex queries across multiple data sources. It provides a detailed guide on implementing Agentic RAG, emphasizing the importance of clear tool descriptions, robust testing, document quality, and a comprehensive monitoring strategy for system performance.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1742076535, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=78, prompt_tokens=1170, total_tokens=1248, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))), delta=None, logprobs=None, additional_kwargs={'prompt_tokens': 1170, 'completion_tokens': 78, 'total_tokens': 1248})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./arize_blogs/agentic_rag.md\", \"r\") as f:\n",
    "    lines = f.read()\n",
    "messages = [\n",
    "    ChatMessage(role=\"system\", content=\"You are a helpful assistant. You describe the information the user provides and summarize it into two concise sentences.\"),\n",
    "    ChatMessage(role=\"user\", content=lines),\n",
    "]\n",
    "response = llm.chat(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The article discusses the concept of Agentic Retrieval-Augmented Generation '\n",
      " '(RAG), an advancement in AI applications that introduces intelligent agents '\n",
      " 'into the retrieval process, enhancing the handling of complex queries across '\n",
      " 'multiple data sources. It provides a detailed guide on implementing Agentic '\n",
      " 'RAG, emphasizing the importance of clear tool descriptions, robust testing, '\n",
      " 'document quality, and a comprehensive monitoring strategy for system '\n",
      " 'performance.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response.message.blocks[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QueryEngineTool(\n",
    "#         query_engine=lyft_engine,\n",
    "#         metadata=ToolMetadata(\n",
    "#             name=\"lyft_10k\",\n",
    "#             description=(\n",
    "#                 \"Provides information about Lyft financials for year 2021. \"\n",
    "#                 \"Use a detailed plain text question as input to the tool.\"\n",
    "#             ),\n",
    "#         ),\n",
    "#     ),\n",
    "\n",
    "tools = []\n",
    "for engine in engines:\n",
    "    with open(f\"./arize_blogs/{engine}\", \"r\") as f:\n",
    "        lines = f.read()\n",
    "    messages = [\n",
    "        ChatMessage(role=\"system\", content=\"You are a helpful assistant. You describe the information the user provides and summarize it into two concise sentences.\"),\n",
    "        ChatMessage(role=\"user\", content=lines),\n",
    "    ]\n",
    "    response = llm.chat(messages)\n",
    "    qetool = QueryEngineTool(\n",
    "        query_engine = engines[engine],\n",
    "        metadata=ToolMetadata(\n",
    "            name=engine,\n",
    "            description=(\n",
    "                f\"{response.message.blocks[0].text}.\"\n",
    "                \"Use a detailed plain text question as input to the\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    tools.append(qetool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article discusses the concept of Agentic Retrieval-Augmented Generation (RAG), an advanced AI application that introduces intelligent agents into the retrieval process to handle complex queries across multiple data sources. It provides a tutorial on building an Agentic RAG system, discusses its implementation, and emphasizes the importance of monitoring and improving its performance using tools like Arize Phoenix..Use a detailed plain text question as input to the\n",
      "agentic_rag.md\n",
      "The blog post discusses a conversation with Yilun Du, a Senior Research Scientist at Google DeepMind, about his latest research paper on a multiagent finetuning framework that improves the performance and diversity of language models. The framework uses a team of specialized models that learn from each other, maintaining diversity in reasoning and sustaining long-term performance gains, and has potential applications in various reasoning tasks and future advancements in language model development..Use a detailed plain text question as input to the\n",
      "multiagent_finetuning.md\n",
      "Arize Copilot, an AI tool designed to streamline workflows and automate debugging, has scaled its support capabilities without slowing down by strategically partnering with AI-powered support solution, RunLLM. The partnership has allowed Arize to enhance technical support quickly, without diverting engineers from core development, and has resulted in a steady growth in Copilot adoption, with plans for further expansion and integration based on customer feedback..Use a detailed plain text question as input to the\n",
      "how_we_scaled_support_without_slowing_down.md\n",
      "The blog post discusses the need for a unified tool for AI evaluation and observability, highlighting the Arize platform that bridges the gap between development and production phases in AI engineering. Arize provides end-to-end observability, evaluation, and troubleshooting capabilities across all AI model types, enabling AI teams to develop, monitor, and iterate their applications with confidence, thereby ensuring high performance across diverse AI models..Use a detailed plain text question as input to the\n",
      "unified_tool_for_evalution_and_observability.md\n",
      "The article discusses the importance of an AI agent router in managing user requests and routing them to the correct function within a system, particularly in large-scale conversational systems. It provides an overview of when to implement an agent router, different implementation approaches such as function calling, intent-based routing, and pure code routing, and best practices for agent router implementation including scope management, developing clear guidelines, and performance monitoring..Use a detailed plain text question as input to the\n",
      "agent_router_best_practices.md\n",
      "DeepSeek is developing AI models that push the boundaries of reasoning and reinforcement learning, aiming to train AI to think more like a human. The company's latest models, DeepSeek R.1 and R.1.0, are making significant strides in inference speed and reasoning abilities, with potential applications in enterprise AI, privacy-focused AI, and traditional machine learning tasks..Use a detailed plain text question as input to the\n",
      "exploring_deepseek.md\n",
      "The blog post discusses the concept of memory and state in Language Learning Model (LLM) applications, explaining how different approaches to memory management can impact performance, cost, and user experience. It also provides insights into various state management strategies, the importance of balancing memory usage, and how to choose the best strategy based on specific use cases..Use a detailed plain text question as input to the\n",
      "memory_and_state_in_llm_applications.md\n",
      "The article provides a comprehensive guide on how to build an AI agent using three different frameworks: smolagents, AutoGen, and LangGraph. It explains the concept of an AI agent, when to use one, and how to implement it using these frameworks, with step-by-step instructions and code examples. The article also discusses the advantages and potential drawbacks of using a framework, and when to consider building an agent from scratch..Use a detailed plain text question as input to the\n",
      "how_to_build_an_ai_agent.md\n"
     ]
    }
   ],
   "source": [
    "descriptions = {}\n",
    "for tool in tools:\n",
    "    print(tool.metadata.description)\n",
    "    print(tool.metadata.name)\n",
    "    descriptions[tool.metadata.name] = tool.metadata.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agentic_rag.md': 'The article discusses the concept of Agentic Retrieval-Augmented Generation (RAG), an advanced AI application that introduces intelligent agents into the retrieval process to handle complex queries across multiple data sources. It provides a tutorial on building an Agentic RAG system, discusses its implementation, and emphasizes the importance of monitoring and improving its performance using tools like Arize Phoenix..Use a detailed plain text question as input to the',\n",
       " 'multiagent_finetuning.md': 'The blog post discusses a conversation with Yilun Du, a Senior Research Scientist at Google DeepMind, about his latest research paper on a multiagent finetuning framework that improves the performance and diversity of language models. The framework uses a team of specialized models that learn from each other, maintaining diversity in reasoning and sustaining long-term performance gains, and has potential applications in various reasoning tasks and future advancements in language model development..Use a detailed plain text question as input to the',\n",
       " 'how_we_scaled_support_without_slowing_down.md': 'Arize Copilot, an AI tool designed to streamline workflows and automate debugging, has scaled its support capabilities without slowing down by strategically partnering with AI-powered support solution, RunLLM. The partnership has allowed Arize to enhance technical support quickly, without diverting engineers from core development, and has resulted in a steady growth in Copilot adoption, with plans for further expansion and integration based on customer feedback..Use a detailed plain text question as input to the',\n",
       " 'unified_tool_for_evalution_and_observability.md': 'The blog post discusses the need for a unified tool for AI evaluation and observability, highlighting the Arize platform that bridges the gap between development and production phases in AI engineering. Arize provides end-to-end observability, evaluation, and troubleshooting capabilities across all AI model types, enabling AI teams to develop, monitor, and iterate their applications with confidence, thereby ensuring high performance across diverse AI models..Use a detailed plain text question as input to the',\n",
       " 'agent_router_best_practices.md': 'The article discusses the importance of an AI agent router in managing user requests and routing them to the correct function within a system, particularly in large-scale conversational systems. It provides an overview of when to implement an agent router, different implementation approaches such as function calling, intent-based routing, and pure code routing, and best practices for agent router implementation including scope management, developing clear guidelines, and performance monitoring..Use a detailed plain text question as input to the',\n",
       " 'exploring_deepseek.md': \"DeepSeek is developing AI models that push the boundaries of reasoning and reinforcement learning, aiming to train AI to think more like a human. The company's latest models, DeepSeek R.1 and R.1.0, are making significant strides in inference speed and reasoning abilities, with potential applications in enterprise AI, privacy-focused AI, and traditional machine learning tasks..Use a detailed plain text question as input to the\",\n",
       " 'memory_and_state_in_llm_applications.md': 'The blog post discusses the concept of memory and state in Language Learning Model (LLM) applications, explaining how different approaches to memory management can impact performance, cost, and user experience. It also provides insights into various state management strategies, the importance of balancing memory usage, and how to choose the best strategy based on specific use cases..Use a detailed plain text question as input to the',\n",
       " 'how_to_build_an_ai_agent.md': 'The article provides a comprehensive guide on how to build an AI agent using three different frameworks: smolagents, AutoGen, and LangGraph. It explains the concept of an AI agent, when to use one, and how to implement it using these frameworks, with step-by-step instructions and code examples. The article also discusses the advantages and potential drawbacks of using a framework, and when to consider building an agent from scratch..Use a detailed plain text question as input to the'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_desc = json.dumps(descriptions, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"descriptions.json\", \"w\") as f:\n",
    "    f.write(json_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(\n",
    "    tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_turns=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 155a9af0-8f74-4943-8beb-908abda7a0ff. Step input: \n",
      "What tool should I use for AI quality?\n",
      "\n",
      "<hint> ALWAYS insert the URL to where you found the information in your response if you see it </hint>\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: The user is asking for a tool for AI quality. The tool \"unified_tool_for_evalution_and_observability.md\" seems to be the most relevant to the user's question as it discusses a platform for AI evaluation and observability. I will use this tool to provide a more detailed answer.\n",
      "Action: unified_tool_for_evalution_and_observability.md\n",
      "Action Input: {'input': 'What tool should I use for AI quality?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: You should consider using Arize. It's a unified AI observability and evaluation platform designed specifically for AI engineers. It provides end-to-end observability, evaluation, and troubleshooting capabilities across all AI model types. This allows you to develop, evaluate, monitor, and iterate your AI models without silos or blind spots. Arize supports GenAI, Computer Vision (CV), and Machine Learning (ML) models, providing a single platform to monitor, evaluate, and iterate across all these models.\n",
      "\u001b[0m> Running step c8bd9aa6-bad1-499a-9a1a-a7a064228cf5. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: You should consider using Arize. It's a unified AI observability and evaluation platform designed specifically for AI engineers. It provides end-to-end observability, evaluation, and troubleshooting capabilities across all AI model types. This allows you to develop, evaluate, monitor, and iterate your AI models without silos or blind spots. Arize supports GenAI, Computer Vision (CV), and Machine Learning (ML) models, providing a single platform to monitor, evaluate, and iterate across all these models. You can find more information in this [source](https://arize.com/unified-tool-for-evaluation-and-observability).\n",
      "\u001b[0mYou should consider using Arize. It's a unified AI observability and evaluation platform designed specifically for AI engineers. It provides end-to-end observability, evaluation, and troubleshooting capabilities across all AI model types. This allows you to develop, evaluate, monitor, and iterate your AI models without silos or blind spots. Arize supports GenAI, Computer Vision (CV), and Machine Learning (ML) models, providing a single platform to monitor, evaluate, and iterate across all these models. You can find more information in this [source](https://arize.com/unified-tool-for-evaluation-and-observability).\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What tool should I use for AI quality?\n",
    "\n",
    "<hint> ALWAYS insert the URL to where you found the information in your response if you see it </hint>\n",
    "\"\"\"\n",
    "\n",
    "response = agent.chat(prompt)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = {}\n",
    "for engine in engines:\n",
    "    with open(f\"./arize_blogs/{engine}\", \"r\") as f:\n",
    "        lines = f.read()\n",
    "    messages = [\n",
    "        ChatMessage(role=\"system\", content=\"\"\"You are a helpful assistant. Extract and return the title and URL to the source .md file.\n",
    "                    <hint> Always give answers in the form of\n",
    "                    Title: (title)\n",
    "                    URL: (url) </hint>\"\"\"),\n",
    "        ChatMessage(role=\"user\", content=lines),\n",
    "    ]\n",
    "    response = llm.chat(messages)\n",
    "    title = response.message.blocks[0].text.split(\"\\n\")[0].split(\": \")[1]\n",
    "    url = response.message.blocks[0].text.split(\"\\n\")[1].split(\": \")[1]\n",
    "\n",
    "    sources[engine] = {\"title\": title,\n",
    "                       \"url\": url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding Agentic RAG http://arize.com/blog/understanding-agentic-rag/\n"
     ]
    }
   ],
   "source": [
    "response.message.blocks[0].text.split(\"\\n\")\n",
    "title = response.message.blocks[0].text.split(\"\\n\")[0].split(\": \")[1]\n",
    "url = response.message.blocks[0].text.split(\"\\n\")[1].split(\": \")[1]\n",
    "print(title, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agentic_rag.md': {'title': 'Understanding Agentic RAG',\n",
       "  'url': 'http://arize.com/blog/understanding-agentic-rag/'},\n",
       " 'multiagent_finetuning.md': {'title': 'Multiagent Finetuning',\n",
       "  'url': 'http://arize.com/blog/multiagent-finetuning-a-conversation-with-researcher-yilun-du/'},\n",
       " 'how_we_scaled_support_without_slowing_down.md': {'title': 'How We Scaled Support in Arize Copilot Without Slowing Down',\n",
       "  'url': 'http://arize.com/blog/how-we-scaled-support-in-arize-copilot-without-slowing-down/'},\n",
       " 'unified_tool_for_evalution_and_observability.md': {'title': 'Why AI Engineers Need a Unified Tool for AI Evaluation and Observability',\n",
       "  'url': 'http://arize.com/blog/why-ai-engineers-need-a-unified-tool-for-ai-evaluation-and-observability/'},\n",
       " 'agent_router_best_practices.md': {'title': 'Best Practices for Building an Agent Router',\n",
       "  'url': 'http://arize.com/blog/best-practices-for-building-an-ai-agent-router/'},\n",
       " 'exploring_deepseek.md': {'title': 'How DeepSeek is Pushing the Boundaries of AI Development',\n",
       "  'url': 'http://arize.com/blog/how-deepseek-is-pushing-the-boundaries-of-ai-development/'},\n",
       " 'memory_and_state_in_llm_applications.md': {'title': 'Memory and State in LLM Applications',\n",
       "  'url': 'http://arize.com/blog/memory-and-state-in-llm-applications/'},\n",
       " 'how_to_build_an_ai_agent.md': {'title': 'How to Build An AI Agent',\n",
       "  'url': 'http://arize.com/blog/how-to-build-an-ai-agent/'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_desc = json.dumps(sources, indent=4)\n",
    "with open(\"sources.json\", \"w\") as f:\n",
    "    f.write(json_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agentic_rag.md': {'title': 'Understanding Agentic RAG',\n",
       "  'url': 'http://arize.com/blog/understanding-agentic-rag/'},\n",
       " 'multiagent_finetuning.md': {'title': 'Multiagent Finetuning',\n",
       "  'url': 'http://arize.com/blog/multiagent-finetuning-a-conversation-with-researcher-yilun-du/'},\n",
       " 'how_we_scaled_support_without_slowing_down.md': {'title': 'How We Scaled Support in Arize Copilot Without Slowing Down',\n",
       "  'url': 'http://arize.com/blog/how-we-scaled-support-in-arize-copilot-without-slowing-down/'},\n",
       " 'unified_tool_for_evalution_and_observability.md': {'title': 'Why AI Engineers Need a Unified Tool for AI Evaluation and Observability',\n",
       "  'url': 'http://arize.com/blog/why-ai-engineers-need-a-unified-tool-for-ai-evaluation-and-observability/'},\n",
       " 'agent_router_best_practices.md': {'title': 'Best Practices for Building an Agent Router',\n",
       "  'url': 'http://arize.com/blog/best-practices-for-building-an-ai-agent-router/'},\n",
       " 'exploring_deepseek.md': {'title': 'How DeepSeek is Pushing the Boundaries of AI Development',\n",
       "  'url': 'http://arize.com/blog/how-deepseek-is-pushing-the-boundaries-of-ai-development/'},\n",
       " 'memory_and_state_in_llm_applications.md': {'title': 'Memory and State in LLM Applications',\n",
       "  'url': 'http://arize.com/blog/memory-and-state-in-llm-applications/'},\n",
       " 'how_to_build_an_ai_agent.md': {'title': 'How to Build An AI Agent',\n",
       "  'url': 'http://arize.com/blog/how-to-build-an-ai-agent/'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./sources.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Understanding Agentic RAG',\n",
       " 'url': 'http://arize.com/blog/understanding-agentic-rag/'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['agentic_rag.md']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ToolMetadata.__init__() got an unexpected keyword argument 'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m     data = json.load(f)\n\u001b[32m      4\u001b[39m description = data[engine]\n\u001b[32m      5\u001b[39m qetool = QueryEngineTool(\n\u001b[32m      6\u001b[39m         query_engine = engines[engine],\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         metadata=\u001b[43mToolMetadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdescription\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUse a detailed plain text question as input to the\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: ToolMetadata.__init__() got an unexpected keyword argument 'title'"
     ]
    }
   ],
   "source": [
    "for engine in engines:\n",
    "    with open(\"descriptions.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    description = data[engine]\n",
    "    qetool = QueryEngineTool(\n",
    "            query_engine = engines[engine],\n",
    "            metadata=ToolMetadata(\n",
    "                name=engine,\n",
    "                description=(\n",
    "                    f\"{description}.\"\n",
    "                    \"Use a detailed plain text question as input to the\"\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
